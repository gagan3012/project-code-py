{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "microdistilmodel.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMM/FrXn3ORdgPx1e38IzGU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gagan3012/project-code-py/blob/master/notebooks/gptneomodel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsTTbIxoSXTc",
        "outputId": "017804ab-255c-4583-eab5-1b2e383ce4ea"
      },
      "source": [
        "lines = ['https://github.com/Garvit244/Leetcode',\n",
        "         'https://github.com/shichao-an/leetcode-python',\n",
        "         'https://github.com/algorhythms/LeetCode',\n",
        "         'https://github.com/wuduhren/leetcode-python',\n",
        "         'https://github.com/csujedihy/lc-all-solutions',\n",
        "         'https://github.com/vJechsmayr/PythonAlgorithms',\n",
        "         'https://github.com/HuberTRoy/leetCode',\n",
        "         'https://github.com/qiyuangong/leetcode',\n",
        "         'https://github.com/MTrajK/coding-problems',\n",
        "         'https://github.com/JushuangQiao/Python-LeetCode',\n",
        "         'https://github.com/Jack-Lee-Hiter/AlgorithmsByPython',\n",
        "         'https://github.com/sapanz/Hackerrank-Problem-Solving-Python-Solutions',\n",
        "         'https://github.com/arsho/Hackerrank_Python_Domain_Solutions',\n",
        "         'https://github.com/swapnanildutta/Hackerrank-Codes',\n",
        "         'https://github.com/markopuza/Competitive-programming-in-Python',\n",
        "         'https://github.com/deepaksood619/Python-Competitive-Programming',\n",
        "         'https://github.com/ndb796/Python-Competitive-Programming-Team-Notes',\n",
        "         'https://github.com/harshitbansal373/python',\n",
        "         'https://github.com/yashagrawal300/python-programs',\n",
        "         'https://github.com/bmegha98/Python-Practice',\n",
        "         'https://github.com/geekcomputers/Python',\n",
        "         'https://github.com/smilejay/python',\n",
        "         'https://github.com/yuzhoujr/leetcode',\n",
        "         'https://github.com/franklingu/leetcode-solutions',\n",
        "         'https://github.com/kumailn/Algorithms',\n",
        "         'https://github.com/Diego-Zulu/leetcode_answers',\n",
        "         'https://github.com/concealedtea/Coding-Interview-Prep',\n",
        "         'https://github.com/Wang-Yann/LeetCodeMe',\n",
        "         'https://github.com/hwm18/MyLeetCode',\n",
        "         'https://github.com/lixiang2017/leetcode',\n",
        "         'https://github.com/thisisshub/DSA',\n",
        "         'https://github.com/criszhou/LeetCode-Python',\n",
        "         'https://github.com/lilianweng/LeetcodePython',\n",
        "         'https://github.com/jioyoung/leetcode',\n",
        "         'https://github.com/Vikktour/Data-Structures-Algorithms-Implementations',\n",
        "         'https://github.com/lkwq007/leetcode-py',\n",
        "         'https://github.com/yz5308/Python_Leetcode',\n",
        "         'https://github.com/Garvit244/Leetcode',\n",
        "         'https://github.com/duanzhihao2017/Leetcode']\n",
        "\n",
        "len(lines)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "39"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-BNj_gi_a8t"
      },
      "source": [
        "lines = ['https://github.com/Garvit244/Leetcode']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ArghELG6QZ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9009c79c-cf07-48dd-c08a-d024a76dd2d8"
      },
      "source": [
        "from subprocess import call\n",
        "import math\n",
        "import os\n",
        "import csv\n",
        "csv_columns = ['text']\n",
        "\n",
        "\n",
        "for line in lines:\n",
        "    call(['git', 'clone', line.strip(), f'resources/{line.strip().split(\"/\")[-1]}'])\n",
        "\n",
        "json_data = []\n",
        "total_files = []\n",
        "count = 0\n",
        "\n",
        "for line in lines:\n",
        "    for currentpath, folders, files in os.walk(f'resources/{line.strip().split(\"/\")[-1]}'):\n",
        "        for file in files:\n",
        "            if file[-3:] == '.py':\n",
        "                count += 1\n",
        "                total_files.append(os.path.join(currentpath, file))\n",
        "\n",
        "print('files: ', len(total_files))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "files:  11352\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JR-q5mlSAWxJ"
      },
      "source": [
        "for file in total_files:\n",
        "    with open(file, \"r\") as f:\n",
        "        try:\n",
        "            t = f.readlines()\n",
        "        except UnicodeDecodeError:\n",
        "            print('DecoderError: ', file)\n",
        "        summary = ''.join(t)\n",
        "        summary = str(summary).strip()\n",
        "        bos_token = '<|title|>'\n",
        "        eos_token = '<|endoftext|>'\n",
        "        data = bos_token + summary + eos_token\n",
        "        json_data.append({'text': data})"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHdBhEpR6cfD"
      },
      "source": [
        "with open(\"data.csv\", 'w') as csvfile:\n",
        "        writer = csv.DictWriter(csvfile, fieldnames=csv_columns)\n",
        "        writer.writeheader()\n",
        "        for data in json_data:\n",
        "            writer.writerow(data)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tH8MJYkm8Ldt"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('/content/data.csv')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oeTMr6_W-o4x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "329eb731-3d31-4ff2-b3be-9c1c539b152a"
      },
      "source": [
        "df['text'][1]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<|title|>\\'\\'\\'\\nIn a string S of lowercase letters, these letters form consecutive groups of the same character.\\n\\nFor example, a string like S = \"abbxxxxzyy\" has the groups \"a\", \"bb\", \"xxxx\", \"z\" and \"yy\".\\n\\nCall a group large if it has 3 or more characters.  We would like the starting and ending positions of every large group.\\n\\nThe final answer should be in lexicographic order.\\n\\n \\n\\nExample 1:\\n\\nInput: \"abbxxxxzzy\"\\nOutput: [[3,6]]\\nExplanation: \"xxxx\" is the single large group with starting  3 and ending positions 6.\\nExample 2:\\n\\nInput: \"abc\"\\nOutput: []\\nExplanation: We have \"a\",\"b\" and \"c\" but no large group.\\nExample 3:\\n\\nInput: \"abcdddeeeeaabbbcd\"\\nOutput: [[3,5],[6,9],[12,14]]\\n\\'\\'\\'\\n\\nclass Solution(object):\\n    def largeGroupPositions(self, S):\\n        \"\"\"\\n        :type S: str\\n        :rtype: List[List[int]]\\n        \"\"\"\\n        if not S:\\n            return []\\n        \\n        result = []\\n        count = 1\\n        prevChar = S[0]\\n        index_i = 0\\n        for index in range(1,len(S)):\\n            if S[index] == prevChar:\\n                count += 1\\n            else:\\n                if count >= 3:\\n                    result.append([index_i, index-1])\\n                \\n                count = 1\\n                prevChar = S[index]\\n                index_i = index\\n                \\n        if count >= 3:\\n            result.append([index_i, len(S)-1])\\n        return result<|endoftext|>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAmmNuZOUqeY",
        "outputId": "96984a1f-ceec-4e6e-aece-0ed5a604b07f"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, eval = train_test_split(df, train_size=.8, random_state=2020)\n",
        "print(len(train))\n",
        "print(len(eval))\n",
        "\n",
        "train = train['text'].tolist()\n",
        "eval = eval['text'].tolist()\n",
        "\n",
        "\n",
        "with open('train_tmp.txt', 'w') as file_handle:\n",
        "  file_handle.write(str(train))\n",
        "\n",
        "with open('eval_tmp.txt', 'w') as file_handle:\n",
        "  file_handle.write(str(eval))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9081\n",
            "2271\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JxD4TxQ-qCt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dded5030-a545-47cb-e1aa-ddede9de0bae"
      },
      "source": [
        "!git clone https://github.com/huggingface/transformers\n",
        "!pip install transformers -U\n",
        "!pip install datasets\n",
        "!pip install wandb"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'transformers' already exists and is not an empty directory.\n",
            "Collecting transformers\n",
            "  Using cached https://files.pythonhosted.org/packages/d5/43/cfe4ee779bbd6a678ac6a97c5a5cdeb03c35f9eaebbb9720b036680f9a2d/transformers-4.6.1-py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied, skipping upgrade: huggingface-hub==0.0.8 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.8)\n",
            "Requirement already satisfied, skipping upgrade: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied, skipping upgrade: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied, skipping upgrade: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (8.0.0)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Installing collected packages: transformers\n",
            "  Found existing installation: transformers 4.4.0\n",
            "    Uninstalling transformers-4.4.0:\n",
            "      Successfully uninstalled transformers-4.4.0\n",
            "Successfully installed transformers-4.6.1\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (1.6.2)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.11.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: tqdm<4.50.0,>=4.27 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.19.5)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: huggingface-hub<0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.0.8)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (20.9)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.7/dist-packages (from datasets) (2021.5.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from datasets) (4.0.1)\n",
            "Requirement already satisfied: pyarrow>=1.0.0<4.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets) (3.0.12)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (2.4.7)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets) (3.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.7/dist-packages (0.10.30)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: subprocess32>=3.5.3 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.5.4)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.1)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.0.1)\n",
            "Requirement already satisfied: sentry-sdk>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.1.0)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Requirement already satisfied: Click>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (8.0.0)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.12.4)\n",
            "Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.1.17)\n",
            "Requirement already satisfied: configparser>=3.8.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.0.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n",
            "Requirement already satisfied: pathtools in /usr/local/lib/python3.7/dist-packages (from wandb) (0.1.2)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2020.12.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.12.0->wandb) (56.1.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.0.7)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.0; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (3.7.4.3)\n",
            "Requirement already satisfied: smmap<5,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (4.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ojIGLxZU1eK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e58b3b62-0402-4c71-a9e6-7df7a705093c"
      },
      "source": [
        "import os\n",
        "os.chdir(\"/content/transformers/\")\n",
        "!pip install .\n",
        "!pwd"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing /content/transformers\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0.dev0) (4.0.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0.dev0) (0.0.45)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0.dev0) (1.19.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0.dev0) (2019.12.20)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0.dev0) (20.9)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0.dev0) (0.10.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0.dev0) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0.dev0) (2.23.0)\n",
            "Requirement already satisfied: huggingface-hub==0.0.8 in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0.dev0) (0.0.8)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0.dev0) (3.0.12)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers==4.7.0.dev0) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers==4.7.0.dev0) (3.4.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.7.0.dev0) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.7.0.dev0) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.7.0.dev0) (8.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.7.0.dev0) (2.4.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.7.0.dev0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.7.0.dev0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.7.0.dev0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.7.0.dev0) (2020.12.5)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building wheel for transformers (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.7.0.dev0-cp37-none-any.whl size=2308963 sha256=4ab8877f32e9e847098be8a87424e407191fa9d0797dfc68e7830e5d739b1bbc\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-7_xkcapg/wheels/23/19/dd/2561a4e47240cf6b307729d58e56f8077dd0c698f5992216cf\n",
            "Successfully built transformers\n",
            "Installing collected packages: transformers\n",
            "  Found existing installation: transformers 4.6.1\n",
            "    Uninstalling transformers-4.6.1:\n",
            "      Successfully uninstalled transformers-4.6.1\n",
            "Successfully installed transformers-4.7.0.dev0\n",
            "/content/transformers\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhF9yjagBBNh",
        "outputId": "79c94ed3-4dbb-4568-e94c-1332d7935cfa"
      },
      "source": [
        "os.chdir(\"/content/transformers/examples/pytorch/\")\n",
        "os.chdir(\"./language-modeling\")\n",
        "!pwd\n",
        "!pip install -r requirements.txt"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/transformers/examples/pytorch/language-modeling\n",
            "Requirement already satisfied: datasets>=1.1.3 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (1.6.2)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (0.1.95)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (3.12.4)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from datasets>=1.1.3->-r requirements.txt (line 1)) (4.0.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets>=1.1.3->-r requirements.txt (line 1)) (1.1.5)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets>=1.1.3->-r requirements.txt (line 1)) (1.19.5)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets>=1.1.3->-r requirements.txt (line 1)) (2.23.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets>=1.1.3->-r requirements.txt (line 1)) (0.70.11.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets>=1.1.3->-r requirements.txt (line 1)) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=1.0.0<4.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets>=1.1.3->-r requirements.txt (line 1)) (3.0.0)\n",
            "Requirement already satisfied: tqdm<4.50.0,>=4.27 in /usr/local/lib/python3.7/dist-packages (from datasets>=1.1.3->-r requirements.txt (line 1)) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets>=1.1.3->-r requirements.txt (line 1)) (20.9)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets>=1.1.3->-r requirements.txt (line 1)) (0.3.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.7/dist-packages (from datasets>=1.1.3->-r requirements.txt (line 1)) (2021.5.0)\n",
            "Requirement already satisfied: huggingface-hub<0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets>=1.1.3->-r requirements.txt (line 1)) (0.0.8)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf->-r requirements.txt (line 3)) (56.1.0)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf->-r requirements.txt (line 3)) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets>=1.1.3->-r requirements.txt (line 1)) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets>=1.1.3->-r requirements.txt (line 1)) (3.4.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets>=1.1.3->-r requirements.txt (line 1)) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets>=1.1.3->-r requirements.txt (line 1)) (2018.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets>=1.1.3->-r requirements.txt (line 1)) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets>=1.1.3->-r requirements.txt (line 1)) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets>=1.1.3->-r requirements.txt (line 1)) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets>=1.1.3->-r requirements.txt (line 1)) (2020.12.5)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets>=1.1.3->-r requirements.txt (line 1)) (2.4.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets>=1.1.3->-r requirements.txt (line 1)) (3.0.12)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "9Z51w4XLXjh-",
        "outputId": "5b3a82e0-ef2b-453a-c4a9-66563a39edc1"
      },
      "source": [
        "import wandb\n",
        "wandb.login()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vh75u-DGFXaO",
        "outputId": "a62dd5e3-929d-4204-a0e5-22bcb23b1930"
      },
      "source": [
        "%env WANDB_PROJECT=project-code-py\n",
        "\n",
        "!python run_clm.py \\\n",
        "--model_type EleutherAI/gpt-neo-125M \\\n",
        "--model_name_or_path EleutherAI/gpt-neo-125M \\\n",
        "--train_file \"/content/train_tmp.txt\" \\\n",
        "--do_train \\\n",
        "--validation_file \"/content/eval_tmp.txt\" \\\n",
        "--do_eval \\\n",
        "--per_device_train_batch_size 1 \\\n",
        "--per_device_eval_batch_size 1 \\\n",
        "--save_steps -1 \\\n",
        "--num_train_epochs 5 \\\n",
        "--fp16 \\\n",
        "--output_dir=\"/content/model\" \\\n",
        "--report_to wandb "
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "env: WANDB_PROJECT=project-code-py\n",
            "2021-05-24 22:35:37.967147: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "05/24/2021 22:35:39 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: True\n",
            "05/24/2021 22:35:39 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(output_dir=/content/model, overwrite_output_dir=False, do_train=True, do_eval=True, do_predict=False, evaluation_strategy=IntervalStrategy.NO, prediction_loss_only=False, per_device_train_batch_size=1, per_device_eval_batch_size=1, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=5e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=5.0, max_steps=-1, lr_scheduler_type=SchedulerType.LINEAR, warmup_ratio=0.0, warmup_steps=0, logging_dir=runs/May24_22-35-39_1798c576f2ce, logging_strategy=IntervalStrategy.STEPS, logging_first_step=False, logging_steps=500, save_strategy=IntervalStrategy.STEPS, save_steps=-1, save_total_limit=None, no_cuda=False, seed=42, fp16=True, fp16_opt_level=O1, fp16_backend=auto, fp16_full_eval=False, local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=[], dataloader_drop_last=False, eval_steps=500, dataloader_num_workers=0, past_index=-1, run_name=/content/model, disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None, ignore_data_skip=False, sharded_ddp=[], deepspeed=None, label_smoothing_factor=0.0, adafactor=False, group_by_length=False, length_column_name=length, report_to=['wandb'], ddp_find_unused_parameters=None, dataloader_pin_memory=True, skip_memory_metrics=True, use_legacy_prediction_loop=False, push_to_hub=False, resume_from_checkpoint=None, _n_gpu=1, mp_parameters=)\n",
            "05/24/2021 22:35:39 - WARNING - datasets.builder -   Using custom data configuration default-36f8ecd3a33a239e\n",
            "05/24/2021 22:35:39 - WARNING - datasets.builder -   Reusing dataset text (/root/.cache/huggingface/datasets/text/default-36f8ecd3a33a239e/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5)\n",
            "[INFO|configuration_utils.py:517] 2021-05-24 22:35:39,836 >> loading configuration file https://huggingface.co/EleutherAI/gpt-neo-125M/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/29380fef22a43cbfb3d3a6c8e2f4fd951459584d87c34e4621b30580a54aca84.350b2531c3ac33139f960e42aa0e8f72fed7248de2cc97c4e34ad41c00234396\n",
            "[INFO|configuration_utils.py:553] 2021-05-24 22:35:39,836 >> Model config GPTNeoConfig {\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPTNeoForCausalLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0,\n",
            "  \"attention_layers\": [\n",
            "    \"global\",\n",
            "    \"local\",\n",
            "    \"global\",\n",
            "    \"local\",\n",
            "    \"global\",\n",
            "    \"local\",\n",
            "    \"global\",\n",
            "    \"local\",\n",
            "    \"global\",\n",
            "    \"local\",\n",
            "    \"global\",\n",
            "    \"local\"\n",
            "  ],\n",
            "  \"attention_types\": [\n",
            "    [\n",
            "      [\n",
            "        \"global\",\n",
            "        \"local\"\n",
            "      ],\n",
            "      6\n",
            "    ]\n",
            "  ],\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embed_dropout\": 0,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": null,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"max_position_embeddings\": 2048,\n",
            "  \"model_type\": \"gpt_neo\",\n",
            "  \"num_heads\": 12,\n",
            "  \"num_layers\": 12,\n",
            "  \"resid_dropout\": 0,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"transformers_version\": \"4.7.0.dev0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257,\n",
            "  \"window_size\": 256\n",
            "}\n",
            "\n",
            "[INFO|configuration_utils.py:517] 2021-05-24 22:35:39,853 >> loading configuration file https://huggingface.co/EleutherAI/gpt-neo-125M/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/29380fef22a43cbfb3d3a6c8e2f4fd951459584d87c34e4621b30580a54aca84.350b2531c3ac33139f960e42aa0e8f72fed7248de2cc97c4e34ad41c00234396\n",
            "[INFO|configuration_utils.py:553] 2021-05-24 22:35:39,854 >> Model config GPTNeoConfig {\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPTNeoForCausalLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0,\n",
            "  \"attention_layers\": [\n",
            "    \"global\",\n",
            "    \"local\",\n",
            "    \"global\",\n",
            "    \"local\",\n",
            "    \"global\",\n",
            "    \"local\",\n",
            "    \"global\",\n",
            "    \"local\",\n",
            "    \"global\",\n",
            "    \"local\",\n",
            "    \"global\",\n",
            "    \"local\"\n",
            "  ],\n",
            "  \"attention_types\": [\n",
            "    [\n",
            "      [\n",
            "        \"global\",\n",
            "        \"local\"\n",
            "      ],\n",
            "      6\n",
            "    ]\n",
            "  ],\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embed_dropout\": 0,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": null,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"max_position_embeddings\": 2048,\n",
            "  \"model_type\": \"gpt_neo\",\n",
            "  \"num_heads\": 12,\n",
            "  \"num_layers\": 12,\n",
            "  \"resid_dropout\": 0,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"transformers_version\": \"4.7.0.dev0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257,\n",
            "  \"window_size\": 256\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:1717] 2021-05-24 22:35:40,033 >> loading file https://huggingface.co/EleutherAI/gpt-neo-125M/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/08c00c4159e921d4c941ac75732643373aba509d9b352a82bbbb043a94058d98.a552555fdda56a1c7c9a285bccfd44ac8e4b9e26c8c9b307831b3ea3ac782b45\n",
            "[INFO|tokenization_utils_base.py:1717] 2021-05-24 22:35:40,033 >> loading file https://huggingface.co/EleutherAI/gpt-neo-125M/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/12305762709d884a770efe7b0c68a7f4bc918da44e956058d43da0d12f7bea20.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
            "[INFO|tokenization_utils_base.py:1717] 2021-05-24 22:35:40,033 >> loading file https://huggingface.co/EleutherAI/gpt-neo-125M/resolve/main/tokenizer.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:1717] 2021-05-24 22:35:40,033 >> loading file https://huggingface.co/EleutherAI/gpt-neo-125M/resolve/main/added_tokens.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:1717] 2021-05-24 22:35:40,033 >> loading file https://huggingface.co/EleutherAI/gpt-neo-125M/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/6c3239a63aaf46ec7625b38abfe41fc2ce0b25f90800aefe6526256340d4ab6d.2b8bf81243d08385c806171bc7ced6d2a0dcc7f896ca637f4e777418f7f0cc3c\n",
            "[INFO|tokenization_utils_base.py:1717] 2021-05-24 22:35:40,033 >> loading file https://huggingface.co/EleutherAI/gpt-neo-125M/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/3cc88b3aa29bb2546db2dc21783292e2a086bb7158c7b5ceddeb24158a85c183.e74f7c3643ee79eb023ead36008be72fe726dada60fa3b2a0569925cfefa1e74\n",
            "[INFO|modeling_utils.py:1155] 2021-05-24 22:35:40,167 >> loading weights file https://huggingface.co/EleutherAI/gpt-neo-125M/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/b0ace3b93ace62067a246888f1e54e2d3ec20807d4d3e27ac602eef3b7091c0b.6525df88f1d5a2d33d95ce2458ef6af9658fe7d1393d6707e0e318779ccc68ff\n",
            "[INFO|modeling_utils.py:1339] 2021-05-24 22:35:42,135 >> All model checkpoint weights were used when initializing GPTNeoForCausalLM.\n",
            "\n",
            "[INFO|modeling_utils.py:1348] 2021-05-24 22:35:42,135 >> All the weights of GPTNeoForCausalLM were initialized from the model checkpoint at EleutherAI/gpt-neo-125M.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPTNeoForCausalLM for predictions without further training.\n",
            "  0% 0/1 [00:00<?, ?ba/s]tcmalloc: large alloc 1088020480 bytes == 0x55ca7e388000 @  0x7f88fef9a2a4 0x7f888f4f52e0 0x7f888f5449e8 0x7f888f4c0ff4 0x7f888f4f4bd3 0x7f888f34b791 0x7f888f3764f6 0x7f888f3761b5 0x7f888f375f2b 0x7f888f36ec38 0x7f888f3e9ad4 0x7f888f347a27 0x7f888f3f1a3d 0x7f888f4351c0 0x7f888f37e3e3 0x7f888f369a7a 0x7f888f345d95 0x7f888f3d502c 0x7f888f3b8a97 0x7f888f3dacc7 0x55c9b198ad54 0x55c9b198aa50 0x55c9b19ff105 0x55c9b19f97ad 0x55c9b198cc9f 0x55c9b198cea1 0x55c9b19fbbb5 0x55c9b19f97ad 0x55c9b198cc9f 0x55c9b198cea1 0x55c9b19fbbb5\n",
            "[WARNING|tokenization_utils_base.py:3171] 2021-05-24 22:36:04,851 >> Token indices sequence length is longer than the specified maximum sequence length for this model (12590703 > 2048). Running this sequence through the model will result in indexing errors\n",
            "[WARNING|run_clm.py:331] 2021-05-24 22:36:04,851 >> ^^^^^^^^^^^^^^^^ Please ignore the warning above - this long input will be chunked into smaller bits before being passed to the model.\n",
            "100% 1/1 [00:24<00:00, 24.42s/ba]\n",
            "100% 1/1 [00:02<00:00,  2.72s/ba]\n",
            "05/24/2021 22:36:09 - WARNING - __main__ -   The tokenizer picked seems to have a very large `model_max_length` (2048). Picking 1024 instead. You can change that default value by passing --block_size xxx.\n",
            "100% 1/1 [00:09<00:00,  9.83s/ba]\n",
            "100% 1/1 [00:01<00:00,  1.24s/ba]\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "[INFO|trainer.py:415] 2021-05-24 22:36:31,772 >> Using amp fp16 backend\n",
            "[INFO|trainer.py:1145] 2021-05-24 22:36:31,782 >> ***** Running training *****\n",
            "[INFO|trainer.py:1146] 2021-05-24 22:36:31,782 >>   Num examples = 12295\n",
            "[INFO|trainer.py:1147] 2021-05-24 22:36:31,782 >>   Num Epochs = 5\n",
            "[INFO|trainer.py:1148] 2021-05-24 22:36:31,782 >>   Instantaneous batch size per device = 1\n",
            "[INFO|trainer.py:1149] 2021-05-24 22:36:31,782 >>   Total train batch size (w. parallel, distributed & accumulation) = 1\n",
            "[INFO|trainer.py:1150] 2021-05-24 22:36:31,782 >>   Gradient Accumulation steps = 1\n",
            "[INFO|trainer.py:1151] 2021-05-24 22:36:31,782 >>   Total optimization steps = 61475\n",
            "[INFO|integrations.py:675] 2021-05-24 22:36:31,783 >> Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgagan3012\u001b[0m (use `wandb login --relogin` to force relogin)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "2021-05-24 22:36:32.998837: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.30\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m/content/model\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  View project at \u001b[34m\u001b[4mhttps://wandb.ai/gagan3012/project-code-py\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  View run at \u001b[34m\u001b[4mhttps://wandb.ai/gagan3012/project-code-py/runs/3lvv6x7q\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in /content/transformers/examples/pytorch/language-modeling/wandb/run-20210524_223631-3lvv6x7q\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb offline` to turn off syncing.\n",
            "\n",
            "  0%|                                     | 191/61475 [00:45<4:01:04,  4.24it/s]Traceback (most recent call last):\n",
            "  File \"run_clm.py\", line 468, in <module>\n",
            "    main()\n",
            "  File \"run_clm.py\", line 421, in main\n",
            "    train_result = trainer.train(resume_from_checkpoint=checkpoint)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\", line 1261, in train\n",
            "    tr_loss += self.training_step(model, inputs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\", line 1745, in training_step\n",
            "    self.scaler.scale(loss).backward()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/tensor.py\", line 245, in backward\n",
            "    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\", line 147, in backward\n",
            "    allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
            "KeyboardInterrupt\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 841\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Program failed with code 255.  Press ctrl-c to abort syncing.\n",
            "/usr/lib/python3.7/multiprocessing/semaphore_tracker.py:144: UserWarning: semaphore_tracker: There appear to be 6 leaked semaphores to clean up at shutdown\n",
            "  len(cache))\n",
            "^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vf7R7mTZggCo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}